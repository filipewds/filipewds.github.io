---
title: "Text Processing"
date: 2020-08-01
tags: [feature engineering, data science, text processing]
header:
  image: "/images/perceptron/percept.jpg"
excerpt: "Feature Engineering, Data Science, Text Processing"
mathjax: "true"
---


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk

from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords, words
from nltk.tokenize import RegexpTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import PorterStemmer

def freq(var, bins=None):
    if bins != None and var.dtype != 'object':
        df = pd.concat([
            var.value_counts(bins=bins),
            var.value_counts(bins=bins, normalize=True).map(lambda x: '{:.1%}'.format(x))
        ], axis=1)

    else:
        df = pd.concat([
            var.value_counts(),
            var.value_counts(normalize=True).map(lambda x: '{:.1%}'.format(x))
        ], axis=1)
    
    df.columns = ['Frequency', 'Percentage']
    return df

def remove_string_special_characters(s): 
      
    # removes special characters with ' ' 
    stripped = re.sub('[^a-zA-z\s]', '', s) 
    stripped = re.sub('_', '', stripped) 
      
    # Change any white space to one space 
    stripped = re.sub('\s+', ' ', stripped) 
      
    # Remove start and end white spaces 
    stripped = stripped.strip() 
    
    return stripped.lower() 
```


```python
df = pd.read_csv("./DataAnalyst.csv")
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Job Title</th>
      <th>Salary Estimate</th>
      <th>Job Description</th>
      <th>Rating</th>
      <th>Company Name</th>
      <th>Location</th>
      <th>Headquarters</th>
      <th>Size</th>
      <th>Founded</th>
      <th>Type of ownership</th>
      <th>Industry</th>
      <th>Sector</th>
      <th>Revenue</th>
      <th>Competitors</th>
      <th>Easy Apply</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Data Analyst, Center on Immigration and Justic...</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Are you eager to roll up your sleeves and harn...</td>
      <td>3.2</td>
      <td>Vera Institute of Justice\n3.2</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>201 to 500 employees</td>
      <td>1961</td>
      <td>Nonprofit Organization</td>
      <td>Social Assistance</td>
      <td>Non-Profit</td>
      <td>$100 to $500 million (USD)</td>
      <td>-1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Quality Data Analyst</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Overview\n\nProvides analytical and technical ...</td>
      <td>3.8</td>
      <td>Visiting Nurse Service of New York\n3.8</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>10000+ employees</td>
      <td>1893</td>
      <td>Nonprofit Organization</td>
      <td>Health Care Services &amp; Hospitals</td>
      <td>Health Care</td>
      <td>$2 to $5 billion (USD)</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Senior Data Analyst, Insights &amp; Analytics Team...</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Weâ€™re looking for a Senior Data Analyst who ha...</td>
      <td>3.4</td>
      <td>Squarespace\n3.4</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>1001 to 5000 employees</td>
      <td>2003</td>
      <td>Company - Private</td>
      <td>Internet</td>
      <td>Information Technology</td>
      <td>Unknown / Non-Applicable</td>
      <td>GoDaddy</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>Data Analyst</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Requisition NumberRR-0001939\nRemote:Yes\nWe c...</td>
      <td>4.1</td>
      <td>Celerity\n4.1</td>
      <td>New York, NY</td>
      <td>McLean, VA</td>
      <td>201 to 500 employees</td>
      <td>2002</td>
      <td>Subsidiary or Business Segment</td>
      <td>IT Services</td>
      <td>Information Technology</td>
      <td>$50 to $100 million (USD)</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>Reporting Data Analyst</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>ABOUT FANDUEL GROUP\n\nFanDuel Group is a worl...</td>
      <td>3.9</td>
      <td>FanDuel\n3.9</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>501 to 1000 employees</td>
      <td>2009</td>
      <td>Company - Private</td>
      <td>Sports &amp; Recreation</td>
      <td>Arts, Entertainment &amp; Recreation</td>
      <td>$100 to $500 million (USD)</td>
      <td>DraftKings</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>




```python
freq(df['Type of ownership'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Frequency</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Company - Private</th>
      <td>1273</td>
      <td>56.5%</td>
    </tr>
    <tr>
      <th>Company - Public</th>
      <td>452</td>
      <td>20.1%</td>
    </tr>
    <tr>
      <th>-1</th>
      <td>163</td>
      <td>7.2%</td>
    </tr>
    <tr>
      <th>Nonprofit Organization</th>
      <td>124</td>
      <td>5.5%</td>
    </tr>
    <tr>
      <th>Subsidiary or Business Segment</th>
      <td>89</td>
      <td>4.0%</td>
    </tr>
    <tr>
      <th>Government</th>
      <td>37</td>
      <td>1.6%</td>
    </tr>
    <tr>
      <th>College / University</th>
      <td>34</td>
      <td>1.5%</td>
    </tr>
    <tr>
      <th>Hospital</th>
      <td>19</td>
      <td>0.8%</td>
    </tr>
    <tr>
      <th>Unknown</th>
      <td>16</td>
      <td>0.7%</td>
    </tr>
    <tr>
      <th>Other Organization</th>
      <td>13</td>
      <td>0.6%</td>
    </tr>
    <tr>
      <th>Contract</th>
      <td>11</td>
      <td>0.5%</td>
    </tr>
    <tr>
      <th>Private Practice / Firm</th>
      <td>9</td>
      <td>0.4%</td>
    </tr>
    <tr>
      <th>School / School District</th>
      <td>9</td>
      <td>0.4%</td>
    </tr>
    <tr>
      <th>Self-employed</th>
      <td>2</td>
      <td>0.1%</td>
    </tr>
    <tr>
      <th>Franchise</th>
      <td>2</td>
      <td>0.1%</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Copying original data frame to preserve from all incoming changes
df2 = df.copy()

# Filter 1 observation with value -1
df2 = df2[df2['Salary Estimate'] != '-1']

# As we saw, every Salary Estimate is an interval
# which we'll get the middle value of it.
df2['MiddleSalaryEstimate'] = df2['Salary Estimate'].str.findall("(\d+)K")\
    .map(lambda x: np.array([*map(int, x)]).mean())
    
# We can easily check the distribution
df2['MiddleSalaryEstimate'].hist()
plt.show()
```


![png]({{ site.url }}{{ site.baseurl }}/images/textproc/output_3_0.png)



```python
interval_5 = df2['MiddleSalaryEstimate'].value_counts(bins=5).index
df2['MidSalEst_Bins'] = pd.cut(df2['MiddleSalaryEstimate'], interval_5)
df2['DescriptionLength'] = df2['Job Description'].map(len)

pd.DataFrame(df2.groupby('MidSalEst_Bins').median()['DescriptionLength']).reset_index()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MidSalEst_Bins</th>
      <th>DescriptionLength</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(56.8, 80.1]</td>
      <td>2814.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(33.383, 56.8]</td>
      <td>2960.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(80.1, 103.4]</td>
      <td>3122.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>(103.4, 126.7]</td>
      <td>2625.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(126.7, 150.0]</td>
      <td>2485.0</td>
    </tr>
  </tbody>
</table>
</div>



With that taken care of, we now have a target variable to predict.


```python
pd.set_option('display.max_rows', 100)
states = df['Location'].str.findall(",\s(\w{2})$").map(max)

freq(states)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Location</th>
      <th>Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CA</th>
      <td>626</td>
      <td>27.8%</td>
    </tr>
    <tr>
      <th>TX</th>
      <td>394</td>
      <td>17.5%</td>
    </tr>
    <tr>
      <th>NY</th>
      <td>345</td>
      <td>15.3%</td>
    </tr>
    <tr>
      <th>IL</th>
      <td>164</td>
      <td>7.3%</td>
    </tr>
    <tr>
      <th>PA</th>
      <td>114</td>
      <td>5.1%</td>
    </tr>
    <tr>
      <th>AZ</th>
      <td>97</td>
      <td>4.3%</td>
    </tr>
    <tr>
      <th>CO</th>
      <td>96</td>
      <td>4.3%</td>
    </tr>
    <tr>
      <th>NC</th>
      <td>90</td>
      <td>4.0%</td>
    </tr>
    <tr>
      <th>NJ</th>
      <td>86</td>
      <td>3.8%</td>
    </tr>
    <tr>
      <th>WA</th>
      <td>54</td>
      <td>2.4%</td>
    </tr>
    <tr>
      <th>VA</th>
      <td>48</td>
      <td>2.1%</td>
    </tr>
    <tr>
      <th>OH</th>
      <td>35</td>
      <td>1.6%</td>
    </tr>
    <tr>
      <th>UT</th>
      <td>33</td>
      <td>1.5%</td>
    </tr>
    <tr>
      <th>FL</th>
      <td>27</td>
      <td>1.2%</td>
    </tr>
    <tr>
      <th>IN</th>
      <td>23</td>
      <td>1.0%</td>
    </tr>
    <tr>
      <th>DE</th>
      <td>11</td>
      <td>0.5%</td>
    </tr>
    <tr>
      <th>GA</th>
      <td>4</td>
      <td>0.2%</td>
    </tr>
    <tr>
      <th>SC</th>
      <td>3</td>
      <td>0.1%</td>
    </tr>
    <tr>
      <th>KS</th>
      <td>3</td>
      <td>0.1%</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_barplot = df['Job Title'].value_counts().reset_index()
df_barplot = df_barplot.sort_values(by='Job Title', ascending=False).iloc[:10]

sns.barplot(data=df_barplot, y='index', x='Job Title')
plt.show()
```


![png]({{ site.url }}{{ site.baseurl }}/images/textproc/output_7_0.png)



```python
np.where(df.Founded == -1, 1, 0).sum()
```




    660




```python
df['Job Description'].value_counts(BINS)
```




    (1870.9, 3736.8]      933
    (-13.66, 1870.9]      609
    (3736.8, 5602.7]      511
    (5602.7, 7468.6]      140
    (7468.6, 9334.5]       42
    (9334.5, 11200.4]      11
    (11200.4, 13066.3]      3
    (16798.1, 18664.0]      2
    (13066.3, 14932.2]      2
    (14932.2, 16798.1]      0
    Name: Job Description, dtype: int64




```python
# Cleaning Job Descriptions

df3 = df2.copy()

# removing special characters
df3['Job Description'] = df3['Job Description'].map(remove_string_special_characters)

# Tokenize
tokenizer = RegexpTokenizer(r"\w+")
df3['Token_JobDesc'] = df3['Job Description'].map(tokenizer.tokenize)

# Stem, Remove stopwords and non english words
stemmer = PorterStemmer()
df3['Token_JobDesc'] = df3['Token_JobDesc']\
    .map(lambda x: [
        stemmer.stem(w) for w in x 
        if w not in stopwords.words('english')
    ])
```


```python
df3['Token_JobDesc']
```




    0       [eager, roll, sleev, har, data, drive, polici,...
    1       [overview, provid, analyt, technic, support, i...
    2       [look, senior, data, analyst, love, mentorship...
    3       [requisit, numberrr, remotey, collabor, creat,...
    4       [fanduel, group, fanduel, group, worldclass, t...
                                  ...                        
    2248    [maintain, system, protect, data, unauthor, us...
    2249    [posit, senior, data, analyst, corpor, audit, ...
    2250    [titl, technic, busi, analyst, sql, data, anal...
    2251    [summari, respons, work, crossfunct, collect, ...
    2252    [bring, bodi, mind, heart, spirit, work, senio...
    Name: Token_JobDesc, Length: 2252, dtype: object




```python
np.where(df3['Job Description']=='',1,0).sum()
```




    1




```python
vectorizer = TfidfVectorizer()
df3['Job Description'].values
#vectors = vectorizer.fit_transform()
```




    array(['are you eager to roll up your sleeves and harness data to drive policy change do you enjoy sifting through complex datasets to illuminate trends and insights do you see yourself working for a valuesdriven organization with a vision to tackle the most pressing injustices of our day we are looking to hire a bright hardworking and creative individual with strong data management skills and a demonstrated commitment to immigrants rights the data analyst will assist with analysis and reporting needs for veras center on immigration and justice cij working across its current projects and future vera initiatives who we are founded in the vera institute is an independent nonpartisan nonprofit organization that combines expertise in research technical assistance and demonstration projects to assist leaders in government and civil society examine justice policy and practice and improve the systems people rely on for justice and safety we study problems that impede human dignity and justice we pilot solutions that are at once transformative and achievable we engage diverse communities in informed debate and we harness the power of evidence to drive effective policy and practice what were doing we are helping to build a movementamong government leaders advocates and the immigration legal services communitytowards universal legal representation for immigrants facing deportation in the face of steppedup immigration enforcement millions of noncitizens are at risk of extended detention and permanent separation from their families and communities veras center on immigration and justice cij partners with government nonprofit partners and communities to improve government systems that affect immigrants and their families cij administers several nationwide legal services programs for immigrants facing deportation develops and implements pilot programs provides technical assistance and conducts independent research and evaluation thats where you come in the data analyst will support the centers programmatic efforts through regular monitoring and reporting of federal government and subcontractor data cij manages several proprietary databases that run on aws and caspio and uses sql r and python to manage data this is an opportunity to help shape an innovative national research and policy agenda as part of a dedicated team of experts working to improve access to justice for noncitizens vera seeks to hire a data analyst to work on various data management projects with its center on immigration and justice cij in collaboration with other data analysts this position will involve work across several projects such as the unaccompanied childrens program ucp a program to increase legal representation for immigrant children facing deportation without a parent or legal guardian the position may cover additional duties for the legal orientation program for custodians lopc which educates the custodians of unaccompanied children about their rights and the immigration court process about the role as a data analyst you will report to a member of the research team and work in close collaboration with other vera staff on ongoing database management monitoring reporting and analysis projects youll support the team by taking ownership of ongoing monitoring and reporting tasks involving large data sets other principal responsibilities will include supporting research staff by preparing large datasets for analysis including merging cleaning and recoding data providing insights into program performance through summary statistics and performance indicators producing timely reports on vera projects for team members and stakeholders improving recurring reporting processes by optimizing code and producing subsequent documentation coordinating database management tasks such as participating in new database design modifying existing databases and communicating with outside engineers and subcontractors developing codebooks and delivering user trainings through webinars and database guides building and maintaining interactive dashboards documenting and correcting data quality issues working with supervisors to prioritize program needs assisting on other projects and tasks as assigned about you youre committed to improving issues affecting immigrants in the united states applicants with personal experiences with the immigration system are especially encouraged to apply youre just getting started in your career and have years of professional or internship experience working with large datasets and preparing data for analysis you have a real enthusiasm for working with data you are comfortable writing queries in sql r andor python or have a solid foundation coding in other programming languages used to manipulate data experience working collaboratively using tools like gitgithub is a plus you have exceptional attention to detail strong problemsolving ability and logical reasoning skills and the ability to detect anomalies in data youre able to work on multiple projects effectively and efficiently both independently and collaboratively with a team this position involves working with secure data that may require government security clearance that clearance is restricted to us citizens and citizens of countries that are party to collective defense agreements with the us the list of those countries is detailed on this webpage an additional requirement of that clearance is residence in the united states for at least three of the last five years how to apply please submit cover letter and resume applications will be considered on a rolling basis until position is filled online submission in pdf format is preferred applications with no cover letter attached will not be considered the cover letter should address your interest in cij and this position however if necessary materials may be mailed or faxed to attn human resources cij data analyst recruitment vera institute of justice th st suite a brooklyn ny fax please use only one method online mail or fax of submission no phone calls please only applicants selected for interviews will be contacted vera is an equal opportunityaffirmative action employer all qualified applicants will be considered for employment without unlawful discrimination based on race color creed national origin sex age disability marital status sexual orientation military status prior record of arrest or conviction citizenship status current employment status or caregiver status vera works to advance justice particularly racial justice in an increasingly multicultural country and globally connected world we value diverse experiences including with regard to educational background and justice system contact and depend on a diverse staff to carry out our mission for more information about vera and cijs work please visit wwwveraorg powered by jazzhr',
           'overview provides analytical and technical support for the integration of multiple data sources used to prepare internal and external reporting for the quality management team and business stakeholders provides support and analytical insight for quality incentive measures hedis measures and quality improvement initiatives monitors analyzes and communicates quality performance related to benchmarks collaborates with clinical and operational teams within quality management as well as with choice clinical operations and business intelligence analytics bia participates in data validation of current reporting and dashboards monitors data integrity of databases and provides recommendation accordingly participates in the development of internal dashboards and databases works under general direction responsibilities provides support and analytical insight for quality incentive measures hedis measures and quality improvement initiatives monitors internal performance against benchmarks through analysis participates in the identification development management and monitoring of quality improvement initiatives collaborates with education staff and makes recommendations for areas of focus in training of assessors and care managers based on analysis of performance trends researches and identifies technicaloperational problems surrounding systemsapplications communicatesrefers complex and unresolved problems to management business intelligence analytics bia andor it conducts ad hoc analyses to help identify operational gaps in care drafts presentations reports publications etc regarding results of analyses communicates results of data analysis to nontechnical audiences participates in prioritization of departmental goals based on identification of operational gaps in care participates in establishing data quality specifications and designs coordinates and supports integrated data systems for analyzing and validating information identifies and makes recommendations for reporting redesigns and platforms for reporting eg automating a manual excel file using macros developing a microstrategy dashboard to replace manually updated excel dashboards moving data storage from excel to access etc as needed trains staff on use of newupdated systems and related topics assists quality management team with database and department reports conducts operations review and analysis of processes and procedures issues report of findings and implements approved changes as required identifies and recommends software needs and applications to accomplish required reporting retrieves compiles reviews and ensures accuracy of data from databases researches and corrects discrepancies as needed analyzes data from internal and external sources identifies and resolves data quality issues before reports are generated works with staff to correct data entry errors analyzes data identifies trends reoccurring problems statistically significant findings and prepares reportssummaries for management review acts as a liaison between quality management choice clinical operations and bia reviews and identifies trends and variances in data and reports researches findings and determines appropriateness of elevating identified issues to leadership for further reviewevaluationaction monitors and maintains files by ensuring that files are current and of relevant nature analyzes and corrects error reports to ensure timely and accurate data develops corrective actions to prevent errors where possible participates in special projects and performs other duties as needed qualifications education bachelors degree in biostatistics epidemiology mathematics computer science social sciences a related field or the equivalent work experience required masters degree with concentration in computer science data science or statistics preferred experience minimum of two years experience performing increasingly complex data analysis and interpretation preferably in a managed care or health care setting required experience with data extraction and manipulation required experience with relational databases and programming experience in sql or plsql required experience with claims data and health plan quality metrics eg hedis qarr preferred proficiency conducting statistical analysis with r sas stata or other statistical software preferred advanced personal computer skills including microsoft word powerpoint excel and access required effective oral written communication and interpersonal skills required ability to multi task in a fastpaced environment required ca',
           'were looking for a senior data analyst who has a love of mentorship data visualization and generating actionable insights from raw data in this role youll have the opportunity to be an organizational influencer who will generate insights with a good degree of autonomy and partner with data science to grow deeper analytical skills you will be joining the insights analytics team a team tasked with developing insights and reporting to support our customers and advisors needs this team sits within the customer operations team but is also connected to the product organization in this role you will work mainly with customer operations stakeholders to set kpis and evaluate the effectiveness of current strategies and workflows you will be involved in many aspects of data operations from data auditing to building dashboards and analytical insights for example you will review the code of more junior analysts and organize coding workshops you will build metrics to evaluate the performance of our advisors eliminating confounding variables and creating weighted measures that account for individual success you will define metrics and create dashboards to track the success of the current strategic direction you will analyze the textbased interactions with our advisors to improve care quality you will also analyze interactions with our chatbot to improve the responses of the bot to match customer expectations you will collaborate with the data engineering team in pursuit of better data modeling and you can collaborate with the data science team on more modelingheavy pursuits like topic modeling or search recommendations you will be a mentor to all other members of the analytics team which demands that you excel in a culture of teaching and learning you will report to the manager of the insights analytics team customer operations in squarespaces new york offices responsibilities design and develop kpis reports and dashboards using bidata visualization tools that clearly track the effectiveness of current strategies execute and communicate impactful analyses using sql and rpython to improve the customer experience and drive customer operations and product roadmap raise the skill level of the analytics team through reviewing code organizing training sessions acting as a mentor and introducing new analytical methods and tools help design and evaluate experiments and pilots setting clear hypotheses and success metrics as well as using the right statistical methods for analyses effectively partner with customer operations and product stakeholders as well as our data engineering team qualifications or more years of experience as a data analyst data scientist or in a relevant field in which you have worked with large datasets to transform data to meaningful insights mastery of sql and experience with rpython experience with dashboardingbi tools like chartio looker tableau experience with data cleaning analysis and presentation to nontechnical stakeholders bachelors degree in a quantitative or logicdriven discipline intellectual curiosity and a deep love of mentorship and generating actionable insights preferred advanced degree masters or phd in quantitative field preferred experience with topic modeling text analyticsnatural language processing we are hiring at various experience levels and were particularly interested in having a diverse team with a broad set of skills and viewpoints if this seems like an opportunity youd like to explore but youre not sure if you qualify we encourage you to apply anyway about squarespace squarespace makes beautiful products to help people with creative ideas succeed by blending elegant design and sophisticated engineering we empower millions of people from individuals and local artists to entrepreneurs shaping the worlds most iconic businesses to share their stories with the world squarespaces team of more than is headquartered in downtown new york city with offices in dublin and portland for more information visit wwwsquarespacecomabout today more than a million people around the globe use squarespace to share different perspectives and experiences with the world not only do we embrace and celebrate the diversity of our customer base but we also strive for the same in our employees at squarespace we are committed to equal employment opportunity regardless of race color ancestry religion sex national origin sexual orientation age citizenship marital status disability gender gender identity or expression or veteran status we are proud to be an equal opportunity workplace',
           ...,
           'title technical business analyst sql data analytics etl location denver co duration months contract notes offshore coordination is required need to attend late eveningearly morning calls experience with sql etl preferred informatica data analytics job description should have years of relevant it experience excellent knowledge sql programming etl side informatica very good knowledge in data analytics area ability to understand data models and data items understanding of etl informatica processes data flows and experience in defining transformationsmappings required evaluating business processes anticipating requirements uncovering areas for improvement and developing and implementing solutions should be able to juggle between multiple business stake holders for various business requirements manage multiple business stake holders and communicate with them effectively and promptly flexible enough to work with offshore time to set up meeting with various offshore technical teams excellent written and verbal communication skill is must performing requirements analysis effectively communicating your insights and plans to crossfunctional team members and management gathering critical information from meetings with various stakeholders and producing useful reports working closely with internal customers it team and managerial staff serving as a liaison between stakeholders onshore and offshore ensuring solutions meet business needs and requirements performing user acceptance testing work with project delivery manager and manage the projects developing project plans and monitoring performance prioritizing initiatives based on business needs and requirements identify the dependencies between the projects business area and prioritize the work accordingly leading ongoing reviews of business processes and developing optimization strategies staying uptodate on the latest process and it advancements to automate and modernize systems conducting meetings and presentations to share ideas and findings should have excellent documentation and presentation skill set monitoring deliverables and ensuring timely completion of projects overall understanding in data and analytics salesforce peoplesoft sharepoint will be an added advantage understanding in real estate and retail domain is a plus',
           'summary responsible for working crossfunctionally to collect data and develop models to determine customer experience drivers utilizing a variety of data sources and techniques utilizes all phases of the analytics lifecycle to derive actionable insights from the end to end customer journey with strength in question design results interpretation and statistical and analytical methods has indepth knowledge in one or more business domains related to the customer experience usually determines own work priorities and has a passion for transforming the customer experience into our best product acts as resource for colleagues with less experience employees at all levels are expected to understand our operating principles make them the guidelines for how you do your job own the customer experience think and act in ways that put our customers first give them seamless digital options at every touchpoint and make them promoters of our products and services know your stuff be enthusiastic learners users and advocates of our gamechanging technology products and services especially our digital tools and experiences win as a team make big things happen by working together and being open to new ideas be an active part of the net promoter system a way of working that brings more employee and customer feedback into the company by joining huddles making call backs and helping us elevate opportunities to do better for our customers drive results and growth respect and promote inclusion and diversity do whats right for each other our customers investors and our communities primary responsibilities identify systemic drivers of end to end customer experience utilizing analytic techniques assess impact of drivers and prioritize initiatives track success of initiatives effectively communicate drivers and priorities to business to drive change core responsibilities collaborates with both the analytic organization and its technology partners to define and publish complex data products provides training to and acts as technical resource for team members acts as a subject matter expert in one or more data subject areas such as sales call center network operation and financial data serves as a team leader within a work group or on crossfunctional teams accepts team lead stretch assignments presents results recommendations and business insights to broader senior leadership team produces a variety of reports graphs summaries and presentations that convey analytic results and align with business needs performs basic research on root cause of data anomalies that are uncovered through normal course of analysis writes complex sql to query large data platforms such as teradata sql server oracle and hadoop to obtain data necessary for analysis combines data as needed from disparate data sources to complete analysis participates in defining business intelligence requirements for projects and data requests participates in multiple enterprise wide projects by providing data analysis to project leaders follows best practices and established policies in business intelligence data analysis maintenance and data quality creates technical documentation internal consistent exercise of independent judgment and discretion in matters of significance regular consistent and punctual attendance must be able to work nights and weekends variable schedules as necessary other duties and responsibilities as assigned education level bachelors degree field of study business business intelligence information systems or related field years of experience generally requires years related experience additional requirements confident with machine learning concepts and how to apply them for analytics intermediate to advanced python andor r skills data wrangling skills to extract and cleanse data for analyses strong skills in data interpretation for insight strong skills in sql and preferred experience with hadoophive strong data visualization and storytelling skills confident with foundational statistical concepts and their application in business',
           'you you bring your body mind heart and spirit to your work as a senior quality data analyst youre equally comfortable with performing data analysisreportingvalidation as well as researching data integrity issues youre great at what you do but you want to be part of something even greater because you believe that while individuals can be strong the right team is invincible us system services is our corporate headquarters in broomfield colorado and is located within the oracle campus scl health is a faithbased nonprofit healthcare organization dedicated to improving the wellbeing of the people we serve benefits are one of the ways we encourage health for you and your family our generous package includes medical dental and vision coverage but health is more than a wellworking body it encompasses body mind and social wellbeing to that end weve launched a healthy living program to address your holistic health healthy living includes financial incentives digital tools tobacco cessation classes counseling and paid time off we also offer financial wellness tools and retirement planning we together well align mission and careers values and workplace well encourage joy and take pride in our integrity well laugh at each others jokes even the bad ones well hello and high five well celebrate milestones and acknowledge the value of spirituality in healing were proud of what we know which includes how much there is to learn your day as a sr quality data analyst you need to know how to create reports and scorecardsdashboards to track the progress of quality safety and risk efforts as it relates to internal and external programs including but not limited to operational performance goals opg integrated quality scorecard iqs cms the joint commission leapfrog etc able to conceptualize and create effective data extracts from multiple sources to complete complex analysis validate data sources appropriate mapping and identify variances ability to identify and clearly articulate data points for inclusion in data tables for identified measures responsible for managing scope and completion of work meeting deadlines and providing deliverables to the customers or end users manage complex projects schedules and facilitates meetings as necessary to complete assignments develop and manage the process for identifying and communicating eg via a report open gaps provide analytic support for internalexternal reporting as requested participate in data governance and validation activities as requested to assure data integrity your experience we hire people not resumes but we also expect excellence which is why we require bachelors degree required or equivalent informatics experience required minimum of five years of experience in data analytics required minimum of three years of experience in a healthcare setting required highly prefer epic experience clarity certification must have prior experience with tableau background and experience in statistics and data management and automation your next move now that you know more about being a sr quality data analyst on our team we hope youll join us at scl health youll reaffirm every day how much you love this work and why you were called to it in the first place located in broomfield co apply today'],
          dtype=object)




```python
feature_names = vectorizer.get_feature_names()
dense = vectors.todense()
denselist = dense.tolist()
df_vectorized = pd.DataFrame(denselist, columns=feature_names)
```


```python
feature_names[3000:4000]
```




    ['beaver',
     'beaverton',
     'became',
     'because',
     'become',
     'becomes',
     'becoming',
     'becubic',
     'becubicdata',
     'bed',
     'bedrock',
     'bedroom',
     'bedspaces',
     'beech',
     'beef',
     'been',
     'beenimplemented',
     'beer',
     'bees',
     'beez',
     'beezwax',
     'before',
     'began',
     'begin',
     'beginner',
     'beginning',
     'beginnings',
     'begins',
     'begun',
     'behalf',
     'behave',
     'behaves',
     'behavior',
     'behavioral',
     'behaviors',
     'behaviour',
     'behaviours',
     'behind',
     'beijing',
     'being',
     'belief',
     'beliefs',
     'believe',
     'believed',
     'believes',
     'bell',
     'bellevue',
     'belly',
     'belong',
     'belonging',
     'beloved',
     'below',
     'belt',
     'belts',
     'ben',
     'bench',
     'benchmark',
     'benchmarking',
     'benchmarks',
     'bend',
     'bending',
     'beneficial',
     'beneficiaries',
     'beneficiary',
     'benefit',
     'benefitapplicants',
     'benefited',
     'benefithub',
     'benefits',
     'benefits401',
     'benefitsguidehouse',
     'benefitsjob',
     'benefitsoverview',
     'benevolence',
     'bennies',
     'bensalem',
     'benselect',
     'bent',
     'berd',
     'bereavement',
     'berglas',
     'berkeley',
     'berlin',
     'berlinki',
     'berman',
     'bermuda',
     'bernadette',
     'bernard',
     'bernstein',
     'bert',
     'berwyn',
     'beside',
     'besides',
     'best',
     'bestpractices',
     'bet',
     'betfair',
     'beth',
     'bethesda',
     'bets',
     'better',
     'bettering',
     'betting',
     'between',
     'bev',
     'beverage',
     'beverages',
     'bevi',
     'bex',
     'beyond',
     'bf76awqnz7',
     'bfa',
     'bflores1',
     'bflsa',
     'bg',
     'bgalley',
     'bgs',
     'bh1',
     'bharat',
     'bhaveshxcutives',
     'bhc',
     'bhf',
     'bhjrs',
     'bhs',
     'bhstaffinggroup',
     'bi',
     'bi360',
     'bia',
     'biannual',
     'bias',
     'biased',
     'biases',
     'bicycle',
     'bid',
     'bidata',
     'bidding',
     'bidi',
     'bidirectional',
     'bids',
     'bieda',
     'big',
     'big4',
     'bigcommerce',
     'bigdata',
     'bigger',
     'biggest',
     'bigquery',
     'biintermediate',
     'bike',
     'biking',
     'bilingual',
     'bility',
     'bill',
     'billable',
     'billboard',
     'billcom',
     'billed',
     'billing',
     'billings',
     'billion',
     'billions',
     'bills',
     'bim',
     'bing',
     'bingdat',
     'binghamton',
     'binomial',
     'bio',
     'biobank',
     'biochemical',
     'biochemistry',
     'biodefense',
     'bioengineering',
     'biohazardous',
     'bioinformatic',
     'bioinformatician',
     'bioinformaticians',
     'bioinformatics',
     'bioinformaticsrequired',
     'biological',
     'biologically',
     'biologics',
     'biologist',
     'biologists',
     'biology',
     'biomarker',
     'biomechanical',
     'biomedical',
     'biopharma',
     'biopharmaceutical',
     'biopharmaclinical',
     'biosafety',
     'bioscience',
     'biosource',
     'biospecimen',
     'biospecimens',
     'biostatistical',
     'biostatistician',
     'biostatisticians',
     'biostatistics',
     'biosystems',
     'biotech',
     'biotechnology',
     'biotechpharmaceutical',
     'birch',
     'birmingham',
     'birst',
     'birth',
     'birthday',
     'bis',
     'bisexual',
     'bistrack',
     'bit',
     'bitbucket',
     'bitcoin',
     'bite',
     'biweekly',
     'biweeklyhours',
     'biz',
     'bizops',
     'biztalk',
     'bjob',
     'bkgzjikoee',
     'bl',
     'black',
     'blackbaud',
     'blackboard',
     'blackjack',
     'blackrock',
     'blackstone',
     'blade',
     'blameless',
     'blaming',
     'blank',
     'bldg',
     'bleeding',
     'blend',
     'blending',
     'blends',
     'blind',
     'blink',
     'blitzer',
     'blizzard',
     'blk',
     'blob',
     'block',
     'blockbuster',
     'blockchain',
     'blocked',
     'blocks',
     'blog',
     'blogs',
     'blogzs',
     'blood',
     'bloom',
     'bloomberg',
     'bloomfield',
     'bloomfieldhomes',
     'blooms',
     'blotter',
     'blowing',
     'blps',
     'blue',
     'bluebonnet',
     'bluekai',
     'bluelabs',
     'blueprint',
     'blueprints',
     'bluevoyant',
     'blueworks',
     'blurring',
     'blvd',
     'bmc',
     'bmctoday',
     'bmd',
     'bmo',
     'bmoharriscareers',
     'bmt',
     'bmx',
     'bnp',
     'bny',
     'bo',
     'board',
     'boarded',
     'boarding',
     'boardpolicies',
     'boards',
     'boasts',
     'bobbili',
     'bobj',
     'boca',
     'bodies',
     'bods',
     'body',
     'boe',
     'boeing',
     'bogotÃ¡',
     'boise',
     'bokeh',
     'bold',
     'boldbold',
     'bolder',
     'boldest',
     'boldly',
     'boldness',
     'bolstering',
     'bolts',
     'bom',
     'boms',
     'bonani',
     'bond',
     'bonding',
     'bonds',
     'bone',
     'bonus',
     'bonuses',
     'book',
     'booked',
     'bookeepers',
     'booking',
     'bookings',
     'bookkeeper',
     'bookkeeping',
     'bookmarks',
     'books',
     'boomi',
     'boost',
     'boosting',
     'boot',
     'bootcamp',
     'boothwyn',
     'boots',
     'bootstrap',
     'bootstrapped',
     'border',
     'borders',
     'boring',
     'born',
     'borne',
     'boroughs',
     'borrower',
     'borrowers',
     'borrowing',
     'borrowworks',
     'borsa',
     'bosch',
     'bose',
     'boston',
     'bot',
     'both',
     'bother',
     'bothered',
     'bots',
     'botten',
     'bottlenecks',
     'bottom',
     'bottoms',
     'bought',
     'boulder',
     'bounce',
     'bouncex',
     'bound',
     'boundaries',
     'boundary',
     'boundlessly',
     'boutique',
     'bowery',
     'bowling',
     'box',
     'boxes',
     'boy',
     'boyceville',
     'bozeman',
     'bp1312',
     'bp4119',
     'bp5145',
     'bpc',
     'bpi',
     'bpm',
     'bpo',
     'bpp',
     'bpr',
     'bq',
     'br',
     'bracing',
     'brad',
     'bradstreet',
     'brag',
     'bragg',
     'brain',
     'brainpower',
     'brains',
     'brainstorm',
     'brainstorming',
     'brainstorms',
     'branch',
     'branches',
     'branching',
     'brand',
     'branded',
     'branding',
     'brandproject',
     'brands',
     'brandwatch',
     'bravest',
     'braviant',
     'braze',
     'brd',
     'brds',
     'breaches',
     'breadth',
     'break',
     'breakaway',
     'breakdown',
     'breakdowndaily',
     'breakers',
     'breakfast',
     'breaking',
     'breaks',
     'breakthrough',
     'breakthroughs',
     'breast',
     'breastfeeding',
     'breathe',
     'breathes',
     'breathing',
     'breed',
     'breeds',
     'brentford',
     'brentwood',
     'brevity',
     'brew',
     'brewer',
     'brewers',
     'brewery',
     'brews',
     'brian',
     'brick',
     'bricks',
     'bridal',
     'bridg',
     'bridge',
     'bridgenet',
     'bridges',
     'bridgewater',
     'bridging',
     'brief',
     'briefing',
     'briefings',
     'briefly',
     'briefs',
     'bright',
     'brighter',
     'brightest',
     'brighthouse',
     'briljent',
     'brilliance',
     'brilliant',
     'bring',
     'bringing',
     'brings',
     'bringsexceptional',
     'brink',
     'brinks',
     'brio',
     'brms',
     'broad',
     'broadband',
     'broadcast',
     'broadcaster',
     'broadcom',
     'broaden',
     'broadened',
     'broadening',
     'broadens',
     'broader',
     'broadest',
     'broadly',
     'broadridge',
     'broadway',
     'brochures',
     'broken',
     'broker',
     'brokerage',
     'brokers',
     'bronx',
     'brook',
     'brookfield',
     'brooklyn',
     'broomfield',
     'bros',
     'broth',
     'brothers',
     'brough',
     'brought',
     'brown',
     'brownie',
     'browse',
     'browser',
     'browsers',
     'bruno',
     'brunswick',
     'brute',
     'bryn',
     'bs',
     'bs4',
     'bsa',
     'bsas',
     'bsc',
     'bsee',
     'bsg',
     'bshanthi',
     'bst',
     'btc',
     'bteq',
     'btg',
     'btginc',
     'bu',
     'bubble',
     'bucket',
     'buckman',
     'bucyrus',
     'budding',
     'budget',
     'budgetary',
     'budgeted',
     'budgeting',
     'budgets',
     'buenos',
     'buess',
     'buffalo',
     'buffers',
     'bug',
     'bugs',
     'build',
     'builder',
     'builders',
     'buildersspecialized',
     'building',
     'buildingbeer',
     'buildingconnected',
     'buildings',
     'buildout',
     'buildpro',
     'builds',
     'built',
     'bulbhead',
     'bulk',
     'bull',
     'bullability',
     'bullassisting',
     'bullcreating',
     'bulldemonstrated',
     'bullenergy',
     'bullensuring',
     'bulleted',
     'bulletin',
     'bulletins',
     'bullets',
     'bullexcellent',
     'bullhigh',
     'bullknowledge',
     'bullminimum',
     'bullmust',
     'bullproviding',
     'bullrefining',
     'bullshit',
     'bullstrong',
     'bullying',
     'bunch',
     'bundled',
     'bundles',
     'bunker',
     'burbank',
     'burden',
     'burdens',
     'bureau',
     'bureaucratic',
     'burgeoning',
     'burlingame',
     'burm',
     'burning',
     'burns',
     'bus',
     'buses',
     'busiest',
     'business',
     'business2',
     'business3',
     'businessanalysis',
     'businesscomcast',
     'businessdata',
     'businesseducation',
     'businesses',
     'businessit',
     'businesslike',
     'businessmissions',
     'businessobjects',
     'businesspeople',
     'businessrequirements',
     'businesssystems',
     'businesssystemsanalysis',
     'businesstech',
     'businesswire',
     'businesswork',
     'bustling',
     'busy',
     'but',
     'butcher',
     'butler',
     'button',
     'buttons',
     'butwith',
     'buy',
     'buyer',
     'buyergenomics',
     'buyers',
     'buying',
     'buyouts',
     'buys',
     'buyside',
     'bv3recruiters',
     'bw',
     'bwic',
     'bx',
     'by',
     'bylawsh',
     'c2',
     'c2agilqtj2',
     'c2c',
     'c2h',
     'c2p',
     'c3b',
     'c4i',
     'c4isr',
     'ca',
     'ca2020',
     'cab',
     'cabinet',
     'cabinets',
     'cable',
     'cables',
     'caboodle',
     'cac',
     'cac40',
     'cache',
     'caci',
     'cacis',
     'cactus',
     'cad',
     'cadastral',
     'cadd',
     'cadence',
     'cads',
     'caduration',
     'caf',
     'cafe',
     'cafeteria',
     'cafeterias',
     'cafewell',
     'caffeine',
     'cafÃ©',
     'caia',
     'cal',
     'calculate',
     'calculated',
     'calculates',
     'calculating',
     'calculation',
     'calculations',
     'calculator',
     'calculatornon',
     'calculus',
     'caledonia',
     'calendar',
     'calendars',
     'caliber',
     'calibrate',
     'calibrates',
     'calibration',
     'calif',
     'california',
     'californiajob',
     'call',
     'called',
     'caller',
     'calling',
     'callour',
     'callouts',
     'calls',
     'calm',
     'calmly',
     'calmness',
     'calpads',
     'calredie',
     'caltrain',
     'cama',
     'camadvgrp',
     'cambridge',
     'camden',
     'came',
     'camp',
     'campaign',
     'campaigning',
     'campaigns',
     'campaignssome',
     'campbell',
     'camps',
     'campus',
     'campuscity',
     'campuses',
     'can',
     'canada',
     'canadian',
     'cancel',
     'cancelling',
     'cancer',
     'candid',
     'candidacy',
     'candidate',
     'candidates',
     'candidatewill',
     'candidateyou',
     'candor',
     'candy',
     'canned',
     'cannes',
     'cannot',
     'canonical',
     'cant',
     'canton',
     'canvas',
     'canvasinfotech',
     'cao',
     'cap',
     'capa',
     'capabilities',
     'capabilitieswhat',
     'capability',
     'capable',
     'capacities',
     'capacitive',
     'capacity',
     'cape',
     'capex',
     'capgemini',
     'capital',
     'capitalize',
     'capitalizes',
     'capitalizing',
     'capitated',
     'capitation',
     'caplease',
     'capm',
     'caposition',
     'capps',
     'capricorn',
     'caps',
     'captiva',
     'captivate',
     'captivating',
     'capture',
     'captured',
     'captures',
     'capturing',
     'car',
     'carando',
     'carb',
     'carbapenem',
     'carbon',
     'card',
     'cardholder',
     'cardholders',
     'cardiac',
     'cardinal',
     'cardiology',
     'cardiometabolic',
     'cardiovascular',
     'cards',
     'care',
     'careadvisors',
     'cared',
     'career',
     'careerbenefits',
     'careercompass',
     'careerportal',
     'careers',
     'careersection',
     'careersemployee',
     'careersh',
     'careersjob',
     'careform',
     'careful',
     'carefully',
     'caregiver',
     'caregivers',
     'careguardian',
     'carejob',
     'cares',
     'caresponsibilities',
     'careware',
     'cargowise',
     'caribbean',
     'caring',
     'caritas',
     'carley',
     'carlisle',
     'carlo',
     'caroffer',
     'carolina',
     'carolinajob',
     'carolinas',
     'carpet',
     'carpeting',
     'carried',
     'carrier',
     'carriers',
     'carries',
     'carrollton',
     'carry',
     'carry1st',
     'carrying',
     'carryingunder',
     'carryout',
     'cars',
     'carson',
     'cart',
     'cartels',
     'cartodb',
     'cartographic',
     'cartography',
     'cartoon',
     'carts',
     'carving',
     'cary',
     'cas',
     'case',
     'caseloads',
     'casemap',
     'casenotebook',
     'cases',
     'casework',
     'cash',
     'cashback',
     'cashflow',
     'casino',
     'casinos',
     'casp',
     'casper',
     'caspio',
     'cass',
     'cassandra',
     'cassidy',
     'cast',
     'caste',
     'castle',
     'castleman',
     'casual',
     'casualty',
     'cat',
     'catalging',
     'catalog',
     'cataloging',
     'catalogingdata',
     'catalogs',
     'catalogue',
     'catalogueyour',
     'cataloguing',
     'catalyses',
     'catalyst',
     'catalysts',
     'catalyze',
     'catastrophes',
     'catastrophic',
     'catasys',
     'catch',
     'catching',
     'categorical',
     'categories',
     'categorization',
     'categorize',
     'categorizing',
     'category',
     'category_',
     'categorywe',
     'cater',
     'catered',
     'catering',
     'caterpillar',
     'caters',
     'cath',
     'catholic',
     'cation',
     'catologing',
     'catravel',
     'causal',
     'causative',
     'cause',
     'caused',
     'causes',
     'caustic',
     'cautious',
     'cav',
     'cavazos',
     'caveats',
     'cb',
     'cb2',
     'cbap',
     'cbeds',
     'cbh',
     'cbioportal',
     'cbip',
     'cbm',
     'cbo',
     'cbp',
     'cbre',
     'cbrose',
     'cbt',
     'cc',
     'cc1',
     'cc223',
     'ccar',
     'ccb',
     'ccbhcs',
     'ccc',
     'cchan',
     'cche',
     'cchp',
     'cci',
     'ccims',
     'ccl',
     'cclf',
     'ccna',
     'ccnp',
     'ccp',
     'ccpa',
     'ccr',
     'ccrc',
     'ccsa',
     'cct',
     'ccure',
     'cd',
     'cda',
     'cdao',
     'cdash',
     'cdb',
     'cdbg',
     'cdc',
     'cde',
     'cdex',
     'cdfi',
     'cdhs',
     'cdisc',
     'cdm',
     'cdma',
     'cdmd',
     'cdmp',
     'cdny',
     'cdo',
     'cdor',
     'cdos',
     'cdp',
     'cdph',
     'cdps',
     'cdr',
     'cdrl',
     'cdt',
     'ce',
     'ce14054',
     'ce14054full',
     'cecelia',
     'cecl',
     'cedar',
     'cedars',
     'cedc',
     'ceded',
     'cedent',
     'ceh',
     'ceiling',
     'celebrate',
     'celebrated',
     'celebrates',
     'celebrating',
     'celebration',
     'celebrations',
     'celebrity',
     'celerity',
     'cell',
     'cells',
     'cellular',
     'celonis',
     'cenergy',
     'cenergyintl',
     'censor',
     'census',
     'cent',
     'centa',
     'centene',
     'centennial',
     'center']




```python
df['Job Description'].map(len).hist()
```




    <AxesSubplot:>




![png]({{ site.url }}{{ site.baseurl }}/images/textproc/output_16_1.png)

