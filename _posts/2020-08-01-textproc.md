---
title: "Text Processing"
date: 2020-08-01
tags: [feature engineering, data science, text processing]
#header:
#  image: "/images/perceptron/percept.jpg"
excerpt: "Feature Engineering, Data Science, Text Processing"
mathjax: "true"
---


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk

from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords, words
from nltk.tokenize import RegexpTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import PorterStemmer

def freq(var, bins=None):
    if bins != None and var.dtype != 'object':
        df = pd.concat([
            var.value_counts(bins=bins),
            var.value_counts(bins=bins, normalize=True).map(lambda x: '{:.1%}'.format(x))
        ], axis=1)

    else:
        df = pd.concat([
            var.value_counts(),
            var.value_counts(normalize=True).map(lambda x: '{:.1%}'.format(x))
        ], axis=1)
    
    df.columns = ['Frequency', 'Percentage']
    return df

def remove_string_special_characters(s): 
      
    # removes special characters with ' ' 
    stripped = re.sub('[^a-zA-z\s]', '', s) 
    stripped = re.sub('_', '', stripped) 
      
    # Change any white space to one space 
    stripped = re.sub('\s+', ' ', stripped) 
      
    # Remove start and end white spaces 
    stripped = stripped.strip() 
    
    return stripped.lower() 
```


```python
df = pd.read_csv("./DataAnalyst.csv")
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Job Title</th>
      <th>Salary Estimate</th>
      <th>Job Description</th>
      <th>Rating</th>
      <th>Company Name</th>
      <th>Location</th>
      <th>Headquarters</th>
      <th>Size</th>
      <th>Founded</th>
      <th>Type of ownership</th>
      <th>Industry</th>
      <th>Sector</th>
      <th>Revenue</th>
      <th>Competitors</th>
      <th>Easy Apply</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Data Analyst, Center on Immigration and Justic...</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Are you eager to roll up your sleeves and harn...</td>
      <td>3.2</td>
      <td>Vera Institute of Justice\n3.2</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>201 to 500 employees</td>
      <td>1961</td>
      <td>Nonprofit Organization</td>
      <td>Social Assistance</td>
      <td>Non-Profit</td>
      <td>$100 to $500 million (USD)</td>
      <td>-1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Quality Data Analyst</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Overview\n\nProvides analytical and technical ...</td>
      <td>3.8</td>
      <td>Visiting Nurse Service of New York\n3.8</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>10000+ employees</td>
      <td>1893</td>
      <td>Nonprofit Organization</td>
      <td>Health Care Services &amp; Hospitals</td>
      <td>Health Care</td>
      <td>$2 to $5 billion (USD)</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Senior Data Analyst, Insights &amp; Analytics Team...</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Weâ€™re looking for a Senior Data Analyst who ha...</td>
      <td>3.4</td>
      <td>Squarespace\n3.4</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>1001 to 5000 employees</td>
      <td>2003</td>
      <td>Company - Private</td>
      <td>Internet</td>
      <td>Information Technology</td>
      <td>Unknown / Non-Applicable</td>
      <td>GoDaddy</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>Data Analyst</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>Requisition NumberRR-0001939\nRemote:Yes\nWe c...</td>
      <td>4.1</td>
      <td>Celerity\n4.1</td>
      <td>New York, NY</td>
      <td>McLean, VA</td>
      <td>201 to 500 employees</td>
      <td>2002</td>
      <td>Subsidiary or Business Segment</td>
      <td>IT Services</td>
      <td>Information Technology</td>
      <td>$50 to $100 million (USD)</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>Reporting Data Analyst</td>
      <td>$37K-$66K (Glassdoor est.)</td>
      <td>ABOUT FANDUEL GROUP\n\nFanDuel Group is a worl...</td>
      <td>3.9</td>
      <td>FanDuel\n3.9</td>
      <td>New York, NY</td>
      <td>New York, NY</td>
      <td>501 to 1000 employees</td>
      <td>2009</td>
      <td>Company - Private</td>
      <td>Sports &amp; Recreation</td>
      <td>Arts, Entertainment &amp; Recreation</td>
      <td>$100 to $500 million (USD)</td>
      <td>DraftKings</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>




```python
freq(df['Type of ownership'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Frequency</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Company - Private</th>
      <td>1273</td>
      <td>56.5%</td>
    </tr>
    <tr>
      <th>Company - Public</th>
      <td>452</td>
      <td>20.1%</td>
    </tr>
    <tr>
      <th>-1</th>
      <td>163</td>
      <td>7.2%</td>
    </tr>
    <tr>
      <th>Nonprofit Organization</th>
      <td>124</td>
      <td>5.5%</td>
    </tr>
    <tr>
      <th>Subsidiary or Business Segment</th>
      <td>89</td>
      <td>4.0%</td>
    </tr>
    <tr>
      <th>Government</th>
      <td>37</td>
      <td>1.6%</td>
    </tr>
    <tr>
      <th>College / University</th>
      <td>34</td>
      <td>1.5%</td>
    </tr>
    <tr>
      <th>Hospital</th>
      <td>19</td>
      <td>0.8%</td>
    </tr>
    <tr>
      <th>Unknown</th>
      <td>16</td>
      <td>0.7%</td>
    </tr>
    <tr>
      <th>Other Organization</th>
      <td>13</td>
      <td>0.6%</td>
    </tr>
    <tr>
      <th>Contract</th>
      <td>11</td>
      <td>0.5%</td>
    </tr>
    <tr>
      <th>Private Practice / Firm</th>
      <td>9</td>
      <td>0.4%</td>
    </tr>
    <tr>
      <th>School / School District</th>
      <td>9</td>
      <td>0.4%</td>
    </tr>
    <tr>
      <th>Self-employed</th>
      <td>2</td>
      <td>0.1%</td>
    </tr>
    <tr>
      <th>Franchise</th>
      <td>2</td>
      <td>0.1%</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Copying original data frame to preserve from all incoming changes
df2 = df.copy()

# Filter 1 observation with value -1
df2 = df2[df2['Salary Estimate'] != '-1']

# As we saw, every Salary Estimate is an interval
# which we'll get the middle value of it.
df2['MiddleSalaryEstimate'] = df2['Salary Estimate'].str.findall("(\d+)K")\
    .map(lambda x: np.array([*map(int, x)]).mean())
    
# We can easily check the distribution
df2['MiddleSalaryEstimate'].hist()
plt.show()
```


![png]({{ site.url }}{{ site.baseurl }}/images/textproc/output_3_0.png)



```python
interval_5 = df2['MiddleSalaryEstimate'].value_counts(bins=5).index
df2['MidSalEst_Bins'] = pd.cut(df2['MiddleSalaryEstimate'], interval_5)
df2['DescriptionLength'] = df2['Job Description'].map(len)

pd.DataFrame(df2.groupby('MidSalEst_Bins').median()['DescriptionLength']).reset_index()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MidSalEst_Bins</th>
      <th>DescriptionLength</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(56.8, 80.1]</td>
      <td>2814.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(33.383, 56.8]</td>
      <td>2960.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(80.1, 103.4]</td>
      <td>3122.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>(103.4, 126.7]</td>
      <td>2625.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(126.7, 150.0]</td>
      <td>2485.0</td>
    </tr>
  </tbody>
</table>
</div>



With that taken care of, we now have a target variable to predict.


```python
pd.set_option('display.max_rows', 100)
states = df['Location'].str.findall(",\s(\w{2})$").map(max)

freq(states)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Location</th>
      <th>Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CA</th>
      <td>626</td>
      <td>27.8%</td>
    </tr>
    <tr>
      <th>TX</th>
      <td>394</td>
      <td>17.5%</td>
    </tr>
    <tr>
      <th>NY</th>
      <td>345</td>
      <td>15.3%</td>
    </tr>
    <tr>
      <th>IL</th>
      <td>164</td>
      <td>7.3%</td>
    </tr>
    <tr>
      <th>PA</th>
      <td>114</td>
      <td>5.1%</td>
    </tr>
    <tr>
      <th>AZ</th>
      <td>97</td>
      <td>4.3%</td>
    </tr>
    <tr>
      <th>CO</th>
      <td>96</td>
      <td>4.3%</td>
    </tr>
    <tr>
      <th>NC</th>
      <td>90</td>
      <td>4.0%</td>
    </tr>
    <tr>
      <th>NJ</th>
      <td>86</td>
      <td>3.8%</td>
    </tr>
    <tr>
      <th>WA</th>
      <td>54</td>
      <td>2.4%</td>
    </tr>
    <tr>
      <th>VA</th>
      <td>48</td>
      <td>2.1%</td>
    </tr>
    <tr>
      <th>OH</th>
      <td>35</td>
      <td>1.6%</td>
    </tr>
    <tr>
      <th>UT</th>
      <td>33</td>
      <td>1.5%</td>
    </tr>
    <tr>
      <th>FL</th>
      <td>27</td>
      <td>1.2%</td>
    </tr>
    <tr>
      <th>IN</th>
      <td>23</td>
      <td>1.0%</td>
    </tr>
    <tr>
      <th>DE</th>
      <td>11</td>
      <td>0.5%</td>
    </tr>
    <tr>
      <th>GA</th>
      <td>4</td>
      <td>0.2%</td>
    </tr>
    <tr>
      <th>SC</th>
      <td>3</td>
      <td>0.1%</td>
    </tr>
    <tr>
      <th>KS</th>
      <td>3</td>
      <td>0.1%</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_barplot = df['Job Title'].value_counts().reset_index()
df_barplot = df_barplot.sort_values(by='Job Title', ascending=False).iloc[:10]

sns.barplot(data=df_barplot, y='index', x='Job Title')
plt.show()
```


![png]({{ site.url }}{{ site.baseurl }}/images/textproc/output_7_0.png)



```python
np.where(df.Founded == -1, 1, 0).sum()
```




    660




```python
df['Job Description'].value_counts(BINS)
```




    (1870.9, 3736.8]      933
    (-13.66, 1870.9]      609
    (3736.8, 5602.7]      511
    (5602.7, 7468.6]      140
    (7468.6, 9334.5]       42
    (9334.5, 11200.4]      11
    (11200.4, 13066.3]      3
    (16798.1, 18664.0]      2
    (13066.3, 14932.2]      2
    (14932.2, 16798.1]      0
    Name: Job Description, dtype: int64




```python
# Cleaning Job Descriptions

df3 = df2.copy()

# removing special characters
df3['Job Description'] = df3['Job Description'].map(remove_string_special_characters)

# Tokenize
tokenizer = RegexpTokenizer(r"\w+")
df3['Token_JobDesc'] = df3['Job Description'].map(tokenizer.tokenize)

# Stem, Remove stopwords and non english words
stemmer = PorterStemmer()
df3['Token_JobDesc'] = df3['Token_JobDesc']\
    .map(lambda x: [
        stemmer.stem(w) for w in x 
        if w not in stopwords.words('english')
    ])
```


```python
df3['Token_JobDesc']
```




    0       [eager, roll, sleev, har, data, drive, polici,...
    1       [overview, provid, analyt, technic, support, i...
    2       [look, senior, data, analyst, love, mentorship...
    3       [requisit, numberrr, remotey, collabor, creat,...
    4       [fanduel, group, fanduel, group, worldclass, t...
                                  ...                        
    2248    [maintain, system, protect, data, unauthor, us...
    2249    [posit, senior, data, analyst, corpor, audit, ...
    2250    [titl, technic, busi, analyst, sql, data, anal...
    2251    [summari, respons, work, crossfunct, collect, ...
    2252    [bring, bodi, mind, heart, spirit, work, senio...
    Name: Token_JobDesc, Length: 2252, dtype: object




```python
np.where(df3['Job Description']=='',1,0).sum()
```




    1




```python
vectorizer = TfidfVectorizer()
df3['Job Description'].values
#vectors = vectorizer.fit_transform()
```

```python
df['Job Description'].map(len).hist()
```




    <AxesSubplot:>




![png]({{ site.url }}{{ site.baseurl }}/images/textproc/output_16_1.png)

